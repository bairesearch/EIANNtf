{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# MNIST Large Untrained Net CNN Exc Inh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fyMqv0I6N7V"
      },
      "source": [
        "Derived from https://www.kaggle.com/code/amyjang/tensorflow-mnist-cnn-tutorial/notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhS7EGDb6N7c",
        "outputId": "71718c7c-6812-4050-dc60-050f3bde4399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras import backend as K\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "QtW5QQroBjB7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "Rp-5VLtgRHyR"
      },
      "outputs": [],
      "source": [
        "positiveWeightImplementation = False\t#orig: True\n",
        "if(not positiveWeightImplementation):\n",
        "    integrateWeights = True\n",
        "    if(integrateWeights):\n",
        "        integrateWeights1 = False    #explicitly declare E/I neurons\n",
        "        integrateWeights2 = True    #implicitly declare E/I neurons   \n",
        "\n",
        "preFinalDenseLayer = False\n",
        "\n",
        "generateUntrainedNetwork = False\n",
        "if(generateUntrainedNetwork):\n",
        "    #only train the last layer\n",
        "    numberOfHiddenLayers = 2    #default: 2    #if 0 then useSVM=True\n",
        "else:\n",
        "    numberOfHiddenLayers = 2   #default: 4\n",
        "\n",
        "if(numberOfHiddenLayers > 1):\n",
        "    addSkipLayers = False   #optional\n",
        "else:\n",
        "    addSkipLayers = False   #mandatory\n",
        "\n",
        "layerSizeBase = 32  #default: 32\n",
        "\n",
        "batch_size = 64 #default: 64\n",
        "epochs = 5  #1  #5\n",
        "\n",
        "debugNoEIneurons = False\n",
        "debugPreTrainWeights = True\n",
        "debugPreTrainOutputs = True\n",
        "debugPostTrainWeights = True\n",
        "debugPostTrainOutputs = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGfQXr--YeL7"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "8efB13kY6N7g"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "jV3cgXgP6N7m"
      },
      "outputs": [],
      "source": [
        "input_shape = (28, 28, 1)\n",
        "\n",
        "x_train=x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_train=x_train / 255.0\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
        "x_test=x_test/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "N60OSnQM6N7n"
      },
      "outputs": [],
      "source": [
        "y_train = tf.one_hot(y_train.astype(np.int32), depth=10)\n",
        "y_test = tf.one_hot(y_test.astype(np.int32), depth=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "0dMzhGd16N7o",
        "outputId": "fee851c9-ad62-49da-8bb9-0df77ad2cd71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0. 0. 0. 0. 0. 1. 0. 0. 0. 0.], shape=(10,), dtype=float32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(x_train[100][:,:,0])\n",
        "print(y_train[100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZ68wASog_I"
      },
      "source": [
        "## Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "3BSgPmfd6N7p"
      },
      "outputs": [],
      "source": [
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "G_TJH-X4qhtI"
      },
      "outputs": [],
      "source": [
        "def activation(x):\n",
        "    return K.maximum(x, 0)  #ReLU\n",
        "\n",
        "def activationExcitatory(x):\n",
        "    return K.maximum(x, 0)  #ReLU\n",
        "\n",
        "def activationInhibitory(x):\n",
        "    if(positiveWeightImplementation):\n",
        "        return -(K.maximum(x, 0))   #ReLU with negative output\n",
        "    else:\n",
        "        return K.maximum(x, 0)  #ReLU\n",
        "\n",
        "def neuronInitializer(shape, dtype=None):\n",
        "    if(positiveWeightImplementation):\n",
        "        print(\"neuronInitializer error: requires !positiveWeightImplementation:integrateWeights\")\n",
        "    else:\n",
        "        if(integrateWeights):\n",
        "            #print(\"shape = \", shape)\n",
        "            w = tf.math.abs(tf.random.normal(shape, dtype=dtype))\n",
        "            wEIsize = w.shape[2]//2\n",
        "            wSignE = tf.ones([w.shape[0], w.shape[1], wEIsize, w.shape[3]])\n",
        "            wSignI = tf.ones([w.shape[0], w.shape[1], wEIsize, w.shape[3]])\n",
        "            wSignI = tf.multiply(wSignI, -1)\n",
        "            wSign = tf.concat([wSignE, wSignI], axis=2)\n",
        "            w = tf.multiply(w, wSign)\n",
        "        else:\n",
        "            print(\"neuronInitializer error: requires !positiveWeightImplementation:integrateWeights\")\n",
        "    return w\n",
        "\n",
        "def excitatoryNeuronInitializer(shape, dtype=None):\n",
        "    return tf.math.abs(tf.random.normal(shape, dtype=dtype))\n",
        "\n",
        "def inhibitoryNeuronInitializer(shape, dtype=None):\n",
        "    if(positiveWeightImplementation):\n",
        "        return tf.math.abs(tf.random.normal(shape, dtype=dtype))\n",
        "    else:\n",
        "        return tf.math.negative(tf.math.abs(tf.random.normal(shape, dtype=dtype)))\n",
        "\n",
        "class negative(tf.keras.constraints.Constraint):\n",
        "    #based on https://www.tensorflow.org/api_docs/python/tf/keras/constraints/Constraint\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def __call__(self, w):\n",
        "        return w * tf.cast(tf.math.less_equal(w, 0.), w.dtype)\n",
        "\n",
        "class positiveOrNegative(tf.keras.constraints.Constraint):\n",
        "    #based on https://www.tensorflow.org/api_docs/python/tf/keras/constraints/Constraint\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def __call__(self, w):\n",
        "        w_shape = w.shape\n",
        "        #print(\"w_shape = \", w_shape)\n",
        "        wEIsize = w.shape[2]//2\n",
        "        wE = w[:, :, 0:wEIsize]\n",
        "        wI = w[:, :, wEIsize:]\n",
        "        wEcheck = tf.greater_equal(wE, 0)\n",
        "        wIcheck = tf.less_equal(wI, 0)\n",
        "        wEcheck = tf.cast(wEcheck, tf.float32)\n",
        "        wIcheck = tf.cast(wIcheck, tf.float32)\n",
        "        wE = tf.multiply(wE, wEcheck)\n",
        "        wI = tf.multiply(wI, wIcheck)\n",
        "        w = tf.concat([wE, wI], axis=2)\n",
        "        return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLN-jkxg6N7q",
        "outputId": "4b95c8a4-9342-46bd-e213-830ba38d9532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_100\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 28, 28, 64)        1664      \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 28, 28, 64)        102464    \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 27, 27, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 27, 27, 64)        0         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 46656)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                466570    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 570,698\n",
            "Trainable params: 570,698\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if(positiveWeightImplementation):\n",
        "    weightConstraint = tf.keras.constraints.non_neg()\n",
        "    constrainBiases = True   #ensure positive biases also\n",
        "    if(constrainBiases):\n",
        "        biasConstraint = tf.keras.constraints.non_neg()\n",
        "        constrainBiasesLastLayer = False\n",
        "        if(constrainBiasesLastLayer):\n",
        "            biasConstraintLastLayer = tf.keras.constraints.non_neg()\n",
        "        else:\n",
        "            biasConstraintLastLayer = None\n",
        "    else:\n",
        "        biasConstraint = None\n",
        "        biasConstraintLastLayer = None\n",
        "else:\n",
        "    if(integrateWeights):\n",
        "        weightConstraint = positiveOrNegative()\n",
        "        biasConstraint = None\n",
        "    else:\n",
        "        weightConstraintPositive = tf.keras.constraints.non_neg()\n",
        "        weightConstraintNegative = negative()\n",
        "        constrainBiases = False\n",
        "        if(constrainBiases):\n",
        "            biasConstraintPositive = tf.keras.constraints.non_neg()\n",
        "            biasConstraintNegative = negative()\n",
        "        else:\n",
        "            biasConstraintPositive = None\n",
        "            biasConstraintNegative = None\n",
        "\n",
        "if(generateUntrainedNetwork):\n",
        "    #only train the last layer\n",
        "    generateLargeNetwork = True\n",
        "else:\n",
        "    generateLargeNetwork = False\n",
        "\n",
        "if(generateLargeNetwork):\n",
        "    largeNetworkRatio = 10    #100\n",
        "    generateLargeNetworkExpansion = False\n",
        "    if(generateLargeNetworkExpansion):\n",
        "        generateLargeNetworkRatioExponential = False\n",
        "else:\n",
        "    generateLargeNetworkRatio = False\n",
        "\n",
        "def getLayerRatio(layerIndex):\n",
        "    layerRatio = 1\n",
        "    if(generateLargeNetwork):\n",
        "        if(generateLargeNetworkExpansion):\n",
        "            if(generateLargeNetworkRatioExponential):\n",
        "                layerRatio = largeNetworkRatio**layerIndex\n",
        "            else:\n",
        "                layerRatio = largeNetworkRatio * layerIndex\n",
        "        else:\n",
        "            layerRatio = largeNetworkRatio\n",
        "    else:\n",
        "        layerRatio = 1\n",
        "    return int(layerRatio)\n",
        "\n",
        "def createEIlayer(layerIndex, h0, firstLayer=False, maxpool2d=None, dropout=None):\n",
        "    layerRatio = getLayerRatio(2)\n",
        "    if(debugNoEIneurons):\n",
        "        h1E = tf.keras.layers.Conv2D(layerSizeBase*layerRatio, (5,5), padding='same')(h0)\n",
        "        h1I = tf.keras.layers.Conv2D(layerSizeBase*layerRatio, (5,5), padding='same')(h0)\n",
        "        h1E = tf.keras.layers.Activation(activationExcitatory)(h1E)\n",
        "        h1I = tf.keras.layers.Activation(activationInhibitory)(h1I)\n",
        "        h1 = tf.keras.layers.Concatenate(axis=2)([h1E, h1I])\n",
        "    else:\n",
        "        if(positiveWeightImplementation):\n",
        "            h1E = tf.keras.layers.Conv2D(layerSizeBase*layerRatio, (5,5), kernel_initializer=excitatoryNeuronInitializer, kernel_constraint=weightConstraint, bias_constraint=biasConstraint, padding='same')(h0)\n",
        "            h1I = tf.keras.layers.Conv2D(layerSizeBase*layerRatio, (5,5), kernel_initializer=inhibitoryNeuronInitializer, kernel_constraint=weightConstraint, bias_constraint=biasConstraint, padding='same')(h0)\n",
        "            h1E = tf.keras.layers.Activation(activationExcitatory)(h1E)\n",
        "            h1I = tf.keras.layers.Activation(activationInhibitory)(h1I)\n",
        "            h1 = tf.keras.layers.Concatenate()([h1E, h1I])\n",
        "            if(maxpool2d is not None):\n",
        "                h1 = tf.keras.layers.MaxPool2D(strides=maxpool2d)(h1)\n",
        "            if(dropout is not None):\n",
        "                h1 = tf.keras.layers.Dropout(dropout)(h1)\n",
        "        else:\n",
        "            if(integrateWeights):\n",
        "                if(integrateWeights1):\n",
        "                    if(firstLayer):\n",
        "                        h1E = tf.keras.layers.Conv2D(layerSizeBase*layerRatio, (5,5), padding='same')(h0)\n",
        "                        h1I = tf.keras.layers.Conv2D(layerSizeBase*layerRatio, (5,5), padding='same')(h0)\n",
        "                    else:\n",
        "                        h1E = tf.keras.layers.Conv2D(layerSizeBase*layerRatio, (5,5), kernel_initializer=neuronInitializer, kernel_constraint=weightConstraint, bias_constraint=biasConstraint, padding='same')(h0)\n",
        "                        h1I = tf.keras.layers.Conv2D(layerSizeBase*layerRatio, (5,5), kernel_initializer=neuronInitializer, kernel_constraint=weightConstraint, bias_constraint=biasConstraint, padding='same')(h0)\n",
        "                    h1E = tf.keras.layers.Activation(activation)(h1E)\n",
        "                    h1I = tf.keras.layers.Activation(activation)(h1I)\n",
        "                    h1 = tf.keras.layers.Concatenate(axis=2)([h1E, h1I])\n",
        "                elif(integrateWeights2):\n",
        "                    if(firstLayer):\n",
        "                        h1 = tf.keras.layers.Conv2D(layerSizeBase*layerRatio*2, (5,5), padding='same')(h0)\n",
        "                    else:\n",
        "                        h1 = tf.keras.layers.Conv2D(layerSizeBase*layerRatio*2, (5,5), kernel_initializer=neuronInitializer, kernel_constraint=weightConstraint, bias_constraint=biasConstraint, padding='same')(h0)\n",
        "                    h1 = tf.keras.layers.Activation(activation)(h1)\n",
        "                if(maxpool2d is not None):\n",
        "                    h1 = tf.keras.layers.MaxPool2D(strides=maxpool2d)(h1)\n",
        "                if(dropout is not None):\n",
        "                    h1 = tf.keras.layers.Dropout(dropout)(h1)\n",
        "            else:\n",
        "                if(firstLayer):\n",
        "                    h1E = tf.keras.layers.Conv2D(layerSizeBase*layerRatio, (5,5), kernel_initializer=excitatoryNeuronInitializer, padding='same')(h0)\n",
        "                    h1I = tf.keras.layers.Conv2D(layerSizeBase*layerRatio, (5,5), kernel_initializer=inhibitoryNeuronInitializer, padding='same')(h0)\n",
        "                else:\n",
        "                    h0E, h0I = h0\n",
        "                    h1Ee = tf.keras.layers.Conv2D(layerSizeBase*layerRatio, (5,5), kernel_initializer=excitatoryNeuronInitializer, kernel_constraint=weightConstraintPositive, bias_constraint=biasConstraintPositive, padding='same')(h0E) #excitatory neuron excitatory inputs\n",
        "                    h1Ei = tf.keras.layers.Conv2D(layerSizeBase*layerRatio, (5,5), kernel_initializer=excitatoryNeuronInitializer, kernel_constraint=weightConstraintNegative, bias_constraint=biasConstraintNegative, padding='same')(h0I) #excitatory neuron inhibitory inputs\n",
        "                    h1Ie = tf.keras.layers.Conv2D(layerSizeBase*layerRatio, (5,5), kernel_initializer=inhibitoryNeuronInitializer, kernel_constraint=weightConstraintPositive, bias_constraint=biasConstraintPositive, padding='same')(h0E) #inhibitory neuron excitatory inputs\n",
        "                    h1Ii = tf.keras.layers.Conv2D(layerSizeBase*layerRatio, (5,5), kernel_initializer=inhibitoryNeuronInitializer, kernel_constraint=weightConstraintNegative, bias_constraint=biasConstraintNegative, padding='same')(h0I) #inhibitory neuron inhibitory inputs\n",
        "                    h1E = tf.keras.layers.Add()([h1Ee, h1Ei])\n",
        "                    h1I = tf.keras.layers.Add()([h1Ie, h1Ii])\n",
        "                h1E = tf.keras.layers.Activation(activationExcitatory)(h1E)\n",
        "                h1I = tf.keras.layers.Activation(activationInhibitory)(h1I)\n",
        "                if(maxpool2d is not None):\n",
        "                    h1E = tf.keras.layers.MaxPool2D(strides=maxpool2d)(h1E)\n",
        "                    h1I = tf.keras.layers.MaxPool2D(strides=maxpool2d)(h1I)\n",
        "                if(dropout is not None):\n",
        "                    h1E = tf.keras.layers.Dropout(dropout)(h1E)\n",
        "                    h1I = tf.keras.layers.Dropout(dropout)(h1I)\n",
        "                h1 = (h1E, h1I)\n",
        "    return h1\n",
        "\n",
        "def concatEIneurons(h):\n",
        "    if(positiveWeightImplementation):\n",
        "        return h\n",
        "    else: \n",
        "        if(integrateWeights):\n",
        "            pass\n",
        "        else:\n",
        "            hE, hI = h\n",
        "            h = tf.keras.layers.Concatenate()([hE, hI])\n",
        "        return h\n",
        "\n",
        "\n",
        "x = tf.keras.layers.Input(shape=input_shape)\n",
        "h0 = x\n",
        "hLast = h0\n",
        "if(numberOfHiddenLayers >= 1):\n",
        "    h1 = createEIlayer(1, h0, firstLayer=True)\n",
        "    hLast = h1\n",
        "if(numberOfHiddenLayers >= 2):\n",
        "    h2 = createEIlayer(2, h1, maxpool2d=(1,1), dropout=0.25)\n",
        "    hLast = h2\n",
        "if(numberOfHiddenLayers >= 3):\n",
        "    h3 = createEIlayer(3, h2)\n",
        "    hLast = h3\n",
        "if(numberOfHiddenLayers >= 4):\n",
        "    h4 = createEIlayer(4, h3, maxpool2d=(2,2))\n",
        "    hLast = h4\n",
        "if(addSkipLayers):\n",
        "    mList = []\n",
        "    if(numberOfHiddenLayers >= 1):\n",
        "        m1 = tf.keras.layers.Flatten()(concatEIneurons(h1))\n",
        "        mList.append(m1)\n",
        "    if(numberOfHiddenLayers >= 2):\n",
        "        m2 = tf.keras.layers.Flatten()(concatEIneurons(h2))\n",
        "        mList.append(m2)\n",
        "    if(numberOfHiddenLayers >= 3):\n",
        "        m3 = tf.keras.layers.Flatten()(concatEIneurons(h3))\n",
        "        mList.append(m3)\n",
        "    if(numberOfHiddenLayers >= 4):\n",
        "        m4 = tf.keras.layers.Flatten()(concatEIneurons(h4))\n",
        "        mList.append(m4)\n",
        "    hLast = tf.keras.layers.concatenate(mList)\n",
        "else:\n",
        "    hLast = concatEIneurons(hLast)\n",
        "\n",
        "hLast = tf.keras.layers.Flatten()(hLast)\n",
        "if(preFinalDenseLayer):\n",
        "    hLast = tf.keras.layers.Dense(128, activation='relu')(hLast)\n",
        "    hLast = tf.keras.layers.Dropout(0.5)(hLast)\n",
        "if(generateUntrainedNetwork):\n",
        "    hLast = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stop_gradient(x))(hLast)\n",
        "y = tf.keras.layers.Dense(num_classes, activation='softmax')(hLast)\n",
        "model = tf.keras.Model(x, y)\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(epsilon=1e-08), loss='categorical_crossentropy', metrics=['acc'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "KM1t_AIX6N7r"
      },
      "outputs": [],
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.995):\n",
        "      print(\"\\nReached 99.5% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "CKVEJ0JYQ2NP"
      },
      "outputs": [],
      "source": [
        "if(debugPreTrainWeights):\n",
        "    testwritefile = open('weightsPreTrain.txt', 'w')\n",
        "    for layerIndex, layer in enumerate(model.layers):\n",
        "        heading = \"layerWeights = \" + str(layerIndex) + \"\\n\"\n",
        "        #print(heading)\n",
        "        testwritefile.write(heading)\n",
        "        weights = layer.get_weights()\n",
        "        #print(weights)\n",
        "        weightsS =  str(weights)\n",
        "        testwritefile.write(weightsS)\n",
        "    testwritefile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "NH6_jeXcQ3B8"
      },
      "outputs": [],
      "source": [
        "if(debugPreTrainOutputs):\n",
        "    testwritefile = open('outputPreTrain.txt', 'w')\n",
        "    xTrainFirstSample = np.expand_dims(x_train[0], axis=0)\n",
        "    for layerIndex, layer in enumerate(model.layers):\n",
        "        heading = \"layerOutputs = \" + str(layerIndex) + \"\\n\"\n",
        "        #print(heading)\n",
        "        testwritefile.write(heading)\n",
        "        func = K.function([model.get_layer(index=0).input], layer.output)\n",
        "        layerOutput = func([xTrainFirstSample])  # input_data is a numpy array\n",
        "        #print(layerOutput)\n",
        "        layerOutputS =  str(layerOutput)\n",
        "        testwritefile.write(layerOutputS)\n",
        "    testwritefile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYpudx2VRL3c"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "F9ocCw_T6N7s",
        "outputId": "1ba1f97c-c868-4b28-cce3-0c87f6865d61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "844/844 [==============================] - 416s 492ms/step - loss: 2.3176 - acc: 0.1144 - val_loss: 2.3019 - val_acc: 0.1050\n",
            "Epoch 2/5\n",
            "830/844 [============================>.] - ETA: 6s - loss: 2.3012 - acc: 0.1135"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-b86f3468ae59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     callbacks=[callbacks])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0TbUrixeokx"
      },
      "outputs": [],
      "source": [
        "if(debugPostTrainWeights):\n",
        "    testwritefile = open('weightsPostTrain.txt', 'w')\n",
        "    for layerIndex, layer in enumerate(model.layers):\n",
        "        heading = \"layerWeights = \" + str(layerIndex) + \"\\n\"\n",
        "        #print(heading)\n",
        "        testwritefile.write(heading)\n",
        "        weights = layer.get_weights()\n",
        "        #print(weights)\n",
        "        weightsS =  str(weights)\n",
        "        testwritefile.write(weightsS)\n",
        "    testwritefile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjnTxUid3GTu"
      },
      "outputs": [],
      "source": [
        "if(debugPostTrainOutputs):\n",
        "    testwritefile = open('outputPostTrain.txt', 'w')\n",
        "    xTrainFirstSample = np.expand_dims(x_train[0], axis=0)\n",
        "    for layerIndex, layer in enumerate(model.layers):\n",
        "        heading = \"layerOutputs = \" + str(layerIndex) + \"\\n\"\n",
        "        #print(heading)\n",
        "        testwritefile.write(heading)\n",
        "        func = K.function([model.get_layer(index=0).input], layer.output)\n",
        "        layerOutput = func([xTrainFirstSample])  # input_data is a numpy array\n",
        "        #print(layerOutput)\n",
        "        layerOutputS =  str(layerOutput)\n",
        "        testwritefile.write(layerOutputS)\n",
        "    testwritefile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr34Iqnn6N7s"
      },
      "source": [
        "## Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuCQbNgW6N7s"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(2,1)\n",
        "ax[0].plot(history.history['loss'], color='b', label=\"Training Loss\")\n",
        "ax[0].plot(history.history['val_loss'], color='r', label=\"Validation Loss\",axes =ax[0])\n",
        "legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "ax[1].plot(history.history['acc'], color='b', label=\"Training Accuracy\")\n",
        "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation Accuracy\")\n",
        "legend = ax[1].legend(loc='best', shadow=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Jz4oEW06N7u"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}